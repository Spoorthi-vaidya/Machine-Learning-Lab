{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=  0 cost=  1.13389\n",
      "iteration=  1000 cost=  0.485\n",
      "iteration=  2000 cost=  0.371346\n",
      "iteration=  3000 cost=  0.305129\n",
      "iteration=  4000 cost=  0.261117\n",
      "iteration=  5000 cost=  0.229163\n",
      "iteration=  6000 cost=  0.204584\n",
      "iteration=  7000 cost=  0.184928\n",
      "iteration=  8000 cost=  0.168772\n",
      "iteration=  9000 cost=  0.155217\n",
      "iteration=  10000 cost=  0.143661\n",
      "iteration=  11000 cost=  0.133683\n",
      "iteration=  12000 cost=  0.124975\n",
      "Validating output for AND GATE\n",
      "[[ 0.00543656]\n",
      " [ 0.13204534]\n",
      " [ 0.13374065]\n",
      " [ 0.81120849]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([2,1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "multiply1=tf.add(tf.matmul(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[0],[0],[0],[1]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for AND GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=  0 cost=  0.425902\n",
      "iteration=  1000 cost=  0.273831\n",
      "iteration=  2000 cost=  0.221601\n",
      "iteration=  3000 cost=  0.185532\n",
      "iteration=  4000 cost=  0.159031\n",
      "iteration=  5000 cost=  0.138802\n",
      "iteration=  6000 cost=  0.122897\n",
      "iteration=  7000 cost=  0.110092\n",
      "iteration=  8000 cost=  0.0995812\n",
      "iteration=  9000 cost=  0.0908126\n",
      "iteration=  10000 cost=  0.0833964\n",
      "iteration=  11000 cost=  0.0770495\n",
      "iteration=  12000 cost=  0.0715613\n",
      "Validating output for OR GATE\n",
      "[[ 0.15094057]\n",
      " [ 0.94024235]\n",
      " [ 0.94150138]\n",
      " [ 0.99929845]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([2,1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "multiply1=tf.add(tf.matmul(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[0],[1],[1],[1]])\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for OR GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=  0 cost=  0.690432\n",
      "iteration=  1000 cost=  0.372526\n",
      "iteration=  2000 cost=  0.240415\n",
      "iteration=  3000 cost=  0.172935\n",
      "iteration=  4000 cost=  0.133452\n",
      "iteration=  5000 cost=  0.107985\n",
      "iteration=  6000 cost=  0.0903613\n",
      "iteration=  7000 cost=  0.0775135\n",
      "iteration=  8000 cost=  0.0677666\n",
      "iteration=  9000 cost=  0.060137\n",
      "iteration=  10000 cost=  0.0540129\n",
      "iteration=  11000 cost=  0.0489948\n",
      "iteration=  12000 cost=  0.0448118\n",
      "Validating output for AND GATE\n",
      "[[ 0.94738775]\n",
      " [ 0.03494395]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.placeholder(tf.float32,shape=[None,1])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights=tf.Variable(tf.random_normal([1,1]),dtype=tf.float32)\n",
    "bias=tf.Variable(tf.random_normal([1]),dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "multiply1=tf.add(tf.matmul(x,weights),bias)\n",
    "z=tf.nn.sigmoid(multiply1)\n",
    "\n",
    "\n",
    "cost=tf.reduce_mean((y*tf.log(z)+(1-y)*tf.log(1-z))*-1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=[[0],[1]]\n",
    "op=[[1],[0]]\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(12001):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for NOT GATE\")\n",
    "    result=sess.run(z,feed_dict={x:inp})\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mahantesh/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "iteration=  0 cost=  0.697228\n",
      "iteration=  1000 cost=  0.69253\n",
      "iteration=  2000 cost=  0.691947\n",
      "iteration=  3000 cost=  0.691348\n",
      "iteration=  4000 cost=  0.690695\n",
      "iteration=  5000 cost=  0.689949\n",
      "iteration=  6000 cost=  0.689066\n",
      "iteration=  7000 cost=  0.687987\n",
      "iteration=  8000 cost=  0.686638\n",
      "iteration=  9000 cost=  0.684916\n",
      "iteration=  10000 cost=  0.682676\n",
      "iteration=  11000 cost=  0.679718\n",
      "iteration=  12000 cost=  0.675758\n",
      "iteration=  13000 cost=  0.670397\n",
      "iteration=  14000 cost=  0.663072\n",
      "iteration=  15000 cost=  0.65301\n",
      "iteration=  16000 cost=  0.639185\n",
      "iteration=  17000 cost=  0.620323\n",
      "iteration=  18000 cost=  0.595046\n",
      "iteration=  19000 cost=  0.562257\n",
      "iteration=  20000 cost=  0.521769\n",
      "iteration=  21000 cost=  0.474917\n",
      "iteration=  22000 cost=  0.42458\n",
      "iteration=  23000 cost=  0.374341\n",
      "iteration=  24000 cost=  0.3273\n",
      "iteration=  25000 cost=  0.285347\n",
      "iteration=  26000 cost=  0.249139\n",
      "iteration=  27000 cost=  0.218488\n",
      "iteration=  28000 cost=  0.192779\n",
      "iteration=  29000 cost=  0.171266\n",
      "iteration=  30000 cost=  0.153227\n",
      "iteration=  31000 cost=  0.138031\n",
      "iteration=  32000 cost=  0.125152\n",
      "iteration=  33000 cost=  0.11416\n",
      "iteration=  34000 cost=  0.104715\n",
      "iteration=  35000 cost=  0.0965412\n",
      "iteration=  36000 cost=  0.0894201\n",
      "iteration=  37000 cost=  0.0831763\n",
      "iteration=  38000 cost=  0.0776686\n",
      "iteration=  39000 cost=  0.0727825\n",
      "iteration=  40000 cost=  0.0684247\n",
      "iteration=  41000 cost=  0.0645189\n",
      "iteration=  42000 cost=  0.0610021\n",
      "iteration=  43000 cost=  0.0578218\n",
      "iteration=  44000 cost=  0.0549342\n",
      "iteration=  45000 cost=  0.0523025\n",
      "iteration=  46000 cost=  0.0498957\n",
      "iteration=  47000 cost=  0.0476872\n",
      "iteration=  48000 cost=  0.0456547\n",
      "iteration=  49000 cost=  0.0437785\n",
      "iteration=  50000 cost=  0.042042\n",
      "iteration=  51000 cost=  0.0404308\n",
      "iteration=  52000 cost=  0.0389321\n",
      "iteration=  53000 cost=  0.0375352\n",
      "iteration=  54000 cost=  0.03623\n",
      "iteration=  55000 cost=  0.0350083\n",
      "iteration=  56000 cost=  0.0338625\n",
      "iteration=  57000 cost=  0.032786\n",
      "iteration=  58000 cost=  0.0317732\n",
      "iteration=  59000 cost=  0.0308186\n",
      "iteration=  60000 cost=  0.0299165\n",
      "iteration=  61000 cost=  0.0290643\n",
      "iteration=  62000 cost=  0.0282567\n",
      "iteration=  63000 cost=  0.0274917\n",
      "iteration=  64000 cost=  0.026765\n",
      "iteration=  65000 cost=  0.0260738\n",
      "iteration=  66000 cost=  0.0254168\n",
      "iteration=  67000 cost=  0.0247911\n",
      "iteration=  68000 cost=  0.0241942\n",
      "iteration=  69000 cost=  0.0236242\n",
      "iteration=  70000 cost=  0.0230796\n",
      "iteration=  71000 cost=  0.0225587\n",
      "iteration=  72000 cost=  0.0220598\n",
      "iteration=  73000 cost=  0.0215816\n",
      "iteration=  74000 cost=  0.021123\n",
      "iteration=  75000 cost=  0.0206841\n",
      "iteration=  76000 cost=  0.0202619\n",
      "iteration=  77000 cost=  0.0198554\n",
      "iteration=  78000 cost=  0.0194643\n",
      "iteration=  79000 cost=  0.0190893\n",
      "Validating output for XOR GATE\n",
      "[[ 0.01855778]\n",
      " [ 0.97556031]\n",
      " [ 0.98300284]\n",
      " [ 0.01561372]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "0\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_uniform([2,2], -1, 1), name=\"weights_1\")\n",
    "weights_2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name=\"weights_2\")\n",
    "\n",
    "\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "multiply1 = tf.sigmoid(tf.matmul(x, weights_1) + Bias1) \n",
    "z = tf.sigmoid(tf.matmul(multiply1, weights_2) + Bias2)\n",
    "\n",
    "cost = tf.reduce_mean(( (y * tf.log(z)) + ((1 - y) * tf.log(1.0 - z)) ) * -1)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[0],[1],[1],[0]])\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(80000):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            sess.run(weights_1)\n",
    "            sess.run(Bias1)\n",
    "            sess.run(weights_2)\n",
    "            sess.run(Bias2)\n",
    "            result=sess.run(z,feed_dict={x:inp})\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for XOR GATE\")\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-NOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mahantesh/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "iteration=  0 cost=  0.726782\n",
      "iteration=  1000 cost=  0.693049\n",
      "iteration=  2000 cost=  0.693015\n",
      "iteration=  3000 cost=  0.693003\n",
      "iteration=  4000 cost=  0.692989\n",
      "iteration=  5000 cost=  0.692975\n",
      "iteration=  6000 cost=  0.692959\n",
      "iteration=  7000 cost=  0.692942\n",
      "iteration=  8000 cost=  0.692923\n",
      "iteration=  9000 cost=  0.692902\n",
      "iteration=  10000 cost=  0.692879\n",
      "iteration=  11000 cost=  0.692853\n",
      "iteration=  12000 cost=  0.692824\n",
      "iteration=  13000 cost=  0.692791\n",
      "iteration=  14000 cost=  0.692754\n",
      "iteration=  15000 cost=  0.692713\n",
      "iteration=  16000 cost=  0.692666\n",
      "iteration=  17000 cost=  0.692612\n",
      "iteration=  18000 cost=  0.69255\n",
      "iteration=  19000 cost=  0.692478\n",
      "iteration=  20000 cost=  0.692396\n",
      "iteration=  21000 cost=  0.692299\n",
      "iteration=  22000 cost=  0.692186\n",
      "iteration=  23000 cost=  0.692052\n",
      "iteration=  24000 cost=  0.691892\n",
      "iteration=  25000 cost=  0.691701\n",
      "iteration=  26000 cost=  0.69147\n",
      "iteration=  27000 cost=  0.69119\n",
      "iteration=  28000 cost=  0.690845\n",
      "iteration=  29000 cost=  0.690419\n",
      "iteration=  30000 cost=  0.689888\n",
      "iteration=  31000 cost=  0.68922\n",
      "iteration=  32000 cost=  0.688372\n",
      "iteration=  33000 cost=  0.68729\n",
      "iteration=  34000 cost=  0.685898\n",
      "iteration=  35000 cost=  0.684102\n",
      "iteration=  36000 cost=  0.681778\n",
      "iteration=  37000 cost=  0.678776\n",
      "iteration=  38000 cost=  0.674916\n",
      "iteration=  39000 cost=  0.670003\n",
      "iteration=  40000 cost=  0.663846\n",
      "iteration=  41000 cost=  0.656288\n",
      "iteration=  42000 cost=  0.647243\n",
      "iteration=  43000 cost=  0.636726\n",
      "iteration=  44000 cost=  0.624848\n",
      "iteration=  45000 cost=  0.611761\n",
      "iteration=  46000 cost=  0.59757\n",
      "iteration=  47000 cost=  0.5822\n",
      "iteration=  48000 cost=  0.565275\n",
      "iteration=  49000 cost=  0.546019\n",
      "iteration=  50000 cost=  0.523262\n",
      "iteration=  51000 cost=  0.495655\n",
      "iteration=  52000 cost=  0.462211\n",
      "iteration=  53000 cost=  0.423057\n",
      "iteration=  54000 cost=  0.379946\n",
      "iteration=  55000 cost=  0.33589\n",
      "iteration=  56000 cost=  0.293998\n",
      "iteration=  57000 cost=  0.256402\n",
      "iteration=  58000 cost=  0.223968\n",
      "iteration=  59000 cost=  0.196616\n",
      "Validating output for XOR GATE\n",
      "[[ 0.79149729]\n",
      " [ 0.11411793]\n",
      " [ 0.21598667]\n",
      " [ 0.82858503]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "0\n",
    "x=tf.placeholder(tf.float32,shape=[None,2])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_uniform([2,2], -1, 1), name=\"weights_1\")\n",
    "weights_2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name=\"weights_2\")\n",
    "\n",
    "\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "multiply1 = tf.sigmoid(tf.matmul(x, weights_1) + Bias1) \n",
    "z = tf.sigmoid(tf.matmul(multiply1, weights_2) + Bias2)\n",
    "\n",
    "cost = tf.reduce_mean(( (y * tf.log(z)) + ((1 - y) * tf.log(1.0 - z)) ) * -1)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "inp=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "op=np.array([[1],[0],[0],[1]])\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(60000):\n",
    "        res,_=sess.run([cost,optimizer],feed_dict={x:inp,y:op})\n",
    "        if i%1000==0:\n",
    "            sess.run(weights_1)\n",
    "            sess.run(Bias1)\n",
    "            sess.run(weights_2)\n",
    "            sess.run(Bias2)\n",
    "            result=sess.run(z,feed_dict={x:inp})\n",
    "            print (\"iteration= \",i,\"cost= \",res)\n",
    "    print (\"Validating output for X-NOR GATE\")\n",
    "    print (result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
